// setup PYTHONPATH (need it for each terminal session)
export PYTHONPATH=/home/cn1h/PycharmProjects/facenet/src

// download LFW
cd
mkdir -p datasets/lfw/raw
tar xvf ~/Downloads/lfw.tgz -C datasets/lfw/raw --strip-components=1

// Align the LFW dataset (output size is 160x160, 10 CPU threads)
for N in {1..10}; do python3 ~/PycharmProjects/facenet/src/align/align_dataset_mtcnn.py ~/PycharmProjects/facenet/datasets/lfw/raw ~/PycharmProjects/facenet/datasets/lfw/lfw_mtcnnpy_160 --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.1 & done
// Align the LFW dataset (output size is 227x227, 10 CPU threads)
for N in {1..10}; do python3 ~/PycharmProjects/facenet/src/align/align_dataset_mtcnn.py ~/PycharmProjects/facenet/datasets/lfw/raw ~/PycharmProjects/facenet/datasets/lfw/lfw_mtcnnpy_227 --image_size 227 --margin 32 --random_order --gpu_memory_fraction 0.1 & done

// Run the test
python3 ~/PycharmProjects/facenet/src/validate_on_lfw.py \
    ~/PycharmProjects/facenet/datasets/lfw/lfw_mtcnnpy_160 \
    ~/PycharmProjects/facenet/models/facenet/20180325-122244 \
    --lfw_pairs ~/PycharmProjects/facenet/data/pairs.txt


// result of 20170512-110547 (Inception-Res-v1, 1M)
trainable_vars 492 (elements 28490852, about 108,68M for float32)
Forward pass duration in 29.386 seconds
Accuracy: 0.992+-0.005
Validation rate: 0.97633+-0.01433 @ FAR=0.00167
Area Under Curve (AUC): 1.000
Equal Error Rate (EER): 0.008

// result of 20180204-160909 (squeezenet, VGGFace2)
trainable_vars 108 (elements 1451130, about 5,53M for float32)
Forward pass duration in 22.730 seconds
Accuracy: 0.983+-0.008
Precision: 0.988+-0.006
Recall: 0.978+-0.014
Validation rate: 0.91200+-0.01851 @ FAR=0.00133
Area Under Curve (AUC): 0.998
Equal Error Rate (EER): 0.018

// result of 20180318-111845 (squeezenet_v1_1, VGGFace2)
Accuracy: 0.978+-0.005
Precision: 0.978+-0.010
Recall: 0.979+-0.008
Validation rate: 0.83600+-0.04038 @ FAR=0.00100
Area Under Curve (AUC): 0.998
Equal Error Rate (EER): 0.022

// result of 20180319-070547 (squeezenet_v1_1, VGGFace2)
Accuracy: 0.977+-0.005
Precision: 0.978+-0.007
Recall: 0.976+-0.012
Validation rate: 0.90233+-0.01592 @ FAR=0.00133
Area Under Curve (AUC): 0.997
Equal Error Rate (EER): 0.023

// 20180320-080617 (squeezenet_v1_1, VGGFace2)
Accuracy: 0.980+-0.004
Precision: 0.983+-0.008
Recall: 0.976+-0.014
Validation rate: 0.90567+-0.02508 @ FAR=0.00167
Area Under Curve (AUC): 0.998
Equal Error Rate (EER): 0.020

// 20180323-080318
// 20180324-080308 (inception_resnet_v2, VGGFace2)
Accuracy: 0.992+-0.005
Precision: 0.995+-0.004
Recall: 0.989+-0.010
Validation rate: 0.95767+-0.01886 @ FAR=0.00067
Area Under Curve (AUC): 0.999
Equal Error Rate (EER): 0.008



// prepare facescrub training dataset
cd ~/PycharmProjects/facenet/datasets/facescrub/raw
// delete big images
sudo find . -size +1M -delete
// this command can run more times if error found, it will not override the exist output
for N in {1..10}; do python3 ~/PycharmProjects/facenet/src/align/align_dataset_mtcnn.py ~/PycharmProjects/facenet/datasets/facescrub/raw ~/PycharmProjects/facenet/datasets/facescrub/facescrub_mtcnnpy_182 --image_size 182 --margin 44 --random_order --gpu_memory_fraction 0.1 & done

for N in {1..10}; do python3 ~/PycharmProjects/facenet/src/align/align_dataset_mtcnn.py ~/PycharmProjects/facenet/datasets/facescrub/raw ~/PycharmProjects/facenet/datasets/facescrub/facescrub_mtcnnpy_250 --image_size 250 --margin 44 --random_order --gpu_memory_fraction 0.1 & done

// prepare VGGFace2 train dataset
for N in {1..10}; do python3 ~/PycharmProjects/facenet/src/align/align_dataset_mtcnn.py ~/PycharmProjects/facenet/datasets/VGGFace2/train ~/PycharmProjects/facenet/datasets/VGGFace2/train_mtcnnpy_182 --image_size 182 --margin 44 --random_order --gpu_memory_fraction 0.1 & done
// prepare VGGFace2 test dataset
for N in {1..10}; do python3 ~/PycharmProjects/facenet/src/align/align_dataset_mtcnn.py ~/PycharmProjects/facenet/datasets/VGGFace2/test ~/PycharmProjects/facenet/datasets/VGGFace2/test_mtcnnpy_182 --image_size 182 --margin 44 --random_order --gpu_memory_fraction 0.1 & done



// train
// --lfw_dir and --lfw_pairs are optional
// --optimizer, choices=['ADAGRAD', 'ADADELTA', 'ADAM', 'RMSPROP', 'MOM']
// check nvidia-smi, make sure no other unnecessary applications are using GPU. e.g. Chrome
// squeezenet, facescrub, image size 160, epochs 10

// change learning rate manually:
// change learning rate schedule file, its content will be read in each epoch. special value 0.0 means stop at that epoch
// or stop manually, restart and set --learning_rate with a positive value and set --continue_ckpt_dir

// --snapshot_at_step: take one additional checkpoint at the step, it simplifies the debug on later step
// --epoch: this is not train on full dataset, it's just a number related to --epoch_size, which means number of batches per epoch
// TODO: --batch_size higher than 102 no log output? (no memory?),
// TODO: also args.batch_size * args.epoch_size too big has same issue,
// TODO: could be a problem from index_queue.dequeue_many(args.batch_size * args.epoch_size, 'index_dequeue')

python3 ~/PycharmProjects/facenet/src/train_softmax.py \
    --snapshot_at_step -1 \
    --learning_rate 0.06 \
    --learning_rate_schedule_file ~/PycharmProjects/facenet/data/learning_rate_schedule_vggface2_ftrl.txt \
    --model_def models.squeezenet_v1_1 \
    --optimizer FTRL \
    --weight_decay 1e-5 \
    --keep_probability 0.8 \
    --center_loss_factor 2e-2 \
    --center_loss_alfa 0.9 \
    --random_crop \
    --random_flip \
    --random_rotate \
    --random_brightness \
    --lfw_epoch_interval 20 \
    --summary_iteration_interval 500 \
    --data_dir ~/PycharmProjects/facenet/datasets/VGGFace2/train_mtcnnpy_182 \
    --image_size 160 \
    --nrof_preprocess_threads 8 \
    --epoch_size 1000 \
    --batch_size 100 \
    --max_nrof_epochs 999 \
    --lfw_dir ~/PycharmProjects/facenet/datasets/lfw/lfw_mtcnnpy_160 \
    --lfw_pairs ~/PycharmProjects/facenet/data/pairs.txt \
    --logs_base_dir ~/PycharmProjects/facenet/logs/facenet/ \
    --models_base_dir ~/PycharmProjects/facenet/models/facenet/ \
    --continue_ckpt_dir ~/PycharmProjects/facenet/models/facenet/20180417-001036 \

//--continue_ckpt_dir ~/PycharmProjects/facenet/models/facenet/20180417-001036 \


// tensorboard
cd
python3 tb --logdir=facenetlogs



// dump vars for deeplearning.js
python3 ~/PycharmProjects/facenet/deeplearningjs/dump_checkpoints/dump_checkpoint_vars.py \
    --model_type=tensorflow \
    --output_dir=~/PycharmProjects/facenet/deeplearningjs/dumped/squeezenet_v1_1_vggface2/ \
    --checkpoint_file=~/PycharmProjects/facenet/models/facenet/20180322-001311/model-20180322-001311.ckpt-271000

