// setup PYTHONPATH (need it for each terminal session)
export PYTHONPATH=/home/cn1h/PycharmProjects/facenet/src

// download LFW
cd
mkdir -p datasets/lfw/raw
tar xvf ~/Downloads/lfw.tgz -C datasets/lfw/raw --strip-components=1

// Align the LFW dataset (output size is 160x160, 12 CPU threads)
for N in {1..10}; do python3 ~/PycharmProjects/facenet/src/align/align_dataset_mtcnn.py ~/PycharmProjects/facenet/datasets/lfw/raw ~/PycharmProjects/facenet/datasets/lfw/lfw_mtcnnpy_160 --image_size 160 --margin 32 --random_order --gpu_memory_fraction 0.1 & done

// Run the test
python3 ~/PycharmProjects/facenet/src/validate_on_lfw.py \
    ~/PycharmProjects/facenet/datasets/lfw/lfw_mtcnnpy_160 \
    ~/PycharmProjects/facenet/models/facenet/20180204-160909 \
    --lfw_pairs ~/PycharmProjects/facenet/data/pairs.txt


// result of 20170512-110547 (Inception-Res-v1, 1M)
trainable_vars 492 (elements 28490852, about 108,68M for float32)
Runnning forward pass on LFW images
Forward pass duration in 29.386 seconds
Accuracy: 0.992+-0.005
Validation rate: 0.97633+-0.01433 @ FAR=0.00167
Area Under Curve (AUC): 1.000
Equal Error Rate (EER): 0.008


// result of 20180303-142138 (SqueenzNet, L1, 60k)
trainable_vars 108 (elements 1451130, about 5,53M for float32)
Runnning forward pass on LFW images
Forward pass duration in 22.730 seconds
Accuracy: 0.905+-0.013
Validation rate: 0.42567+-0.05158 @ FAR=0.00100
Area Under Curve (AUC): 0.968
Equal Error Rate (EER): 0.093


// result of 20180303-192233 (Inception-Res-v1, 60k)
trainable_vars 492
Runnning forward pass on LFW images
Forward pass duration in 26.978 seconds
Accuracy: 0.902+-0.011
Validation rate: 0.50367+-0.03831 @ FAR=0.00167
Area Under Curve (AUC): 0.963
Equal Error Rate (EER): 0.100

// result of 20180204-160909 (squeenznet, VGGFace2)
trainable_vars 108
Runnning forward pass on LFW images
Forward pass duration in 29.841 seconds
Accuracy: 0.983+-0.008
Validation rate: 0.91200+-0.01851 @ FAR=0.00133
Area Under Curve (AUC): 0.998
Equal Error Rate (EER): 0.018



// prepare facescrub training dataset
cd ~/PycharmProjects/facenet/datasets/facescrub/raw
// delete big images
sudo find . -size +1M -delete
// this command can run more times if error found, it will not override the exist output
for N in {1..10}; do python3 ~/PycharmProjects/facenet/src/align/align_dataset_mtcnn.py ~/PycharmProjects/facenet/datasets/facescrub/raw ~/PycharmProjects/facenet/datasets/facescrub/facescrub_mtcnnpy_182 --image_size 182 --margin 44 --random_order --gpu_memory_fraction 0.1 & done

// train
// --lfw_dir and --lfw_pairs are optional
// --optimizer, choices=['ADAGRAD', 'ADADELTA', 'ADAM', 'RMSPROP', 'MOM']
// check nvidia-smi, make sure no other unnecessary applications are using GPU. e.g. Chrome
// squeezenet, facescrub, image size 160, epochs 10
// change learning rate manually:
// --learning_rate with a positive value and remove --learning_rate_schedule_file, set --continue_ckpt_dir
// --snapshot_at_step: take one additional checkpoint at the step, it simplifies the debug on later step
python3 ~/PycharmProjects/facenet/src/train_softmax.py \
    --snapshot_at_step -1 \
    --learning_rate -1 \
    --learning_rate_schedule_file ~/PycharmProjects/facenet/data/learning_rate_schedule_classifier_facescrub.txt \
    --keep_probability 0.8 \
    --weight_decay 1e-5 \
    --center_loss_factor 1e-2 \
    --center_loss_alfa 0.9 \
    --model_def models.inception_resnet_v1 \
    --optimizer ADAM \
    --max_nrof_epochs 10 \
    --epoch_size 1000 \
    --random_crop \
    --random_flip \
    --logs_base_dir ~/PycharmProjects/facenet/logs/facenet/ \
    --models_base_dir ~/PycharmProjects/facenet/models/facenet/ \
    --data_dir ~/PycharmProjects/facenet/datasets/facescrub/facescrub_mtcnnpy_182 \
    --image_size 160 \
    --lfw_dir ~/PycharmProjects/facenet/datasets/lfw/lfw_mtcnnpy_160 \
    --lfw_pairs ~/PycharmProjects/facenet/data/pairs.txt

//--continue_ckpt_dir ~/PycharmProjects/facenet/models/facenet/20180303-154207 \


// dump vars for deeplearning.js
python3 ~/PycharmProjects/facenet/deeplearningjs/dump_checkpoints/dump_checkpoint_vars.py \
    --model_type=tensorflow \
    --output_dir=~/PycharmProjects/facenet/deeplearningjs/dumped/squeezenet_10_facescrub_l1/ \
    --checkpoint_file=~/PycharmProjects/facenet/models/facenet/20180303-142138/model-20180303-142138.ckpt-10000
